{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>fakeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nRev Dr. Childress is available...</td>\n",
       "      <td>BlackGenocide.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nSpeaking Engagement Request\\n\\n\\n\\nContact...</td>\n",
       "      <td>Request Speaking Engagement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"…I have set before you life and death, blessi...</td>\n",
       "      <td>BlackGenocide.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why We Oppose Planned Parent Hood ( The follow...</td>\n",
       "      <td>Why We Oppose Planned Parenthood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n",
       "      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            content  \\\n",
       "0     0  \\n\\n\\n\\n\\n\\n\\n\\nRev Dr. Childress is available...   \n",
       "1     0  \\n\\nSpeaking Engagement Request\\n\\n\\n\\nContact...   \n",
       "2     0  \"…I have set before you life and death, blessi...   \n",
       "3     0  Why We Oppose Planned Parent Hood ( The follow...   \n",
       "4     1  Headline: Bitcoin & Blockchain Searches Exceed...   \n",
       "\n",
       "                                               title  fakeness  \n",
       "0                                  BlackGenocide.org         1  \n",
       "1                        Request Speaking Engagement         1  \n",
       "2                                  BlackGenocide.org         1  \n",
       "3                   Why We Oppose Planned Parenthood         1  \n",
       "4  Surprise: Socialist Hotbed Of Venezuela Has Lo...         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_msgpack(\"./combined.msg\")\n",
    "df['fakeness'] = 0\n",
    "df.loc[df['type'] < 2, 'fakeness'] = 1\n",
    "smaller = df.groupby('fakeness').head(15000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = text_clf.fit(smaller.content.values, smaller.fakeness.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(smaller.content.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(np.mean(predicted == smaller.fakeness.values) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       real       0.90      0.92      0.91     15000\n",
      "       fake       0.91      0.90      0.91     15000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(smaller.fakeness, predicted, target_names=['real', 'fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13728,  1272],\n",
       "       [ 1485, 13515]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(smaller.fakeness, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Here\n",
    "----\n",
    "\n",
    "90% accuracy is okay if the model is a component of a larger system to differentiate between likely fake and likely true news.\n",
    "\n",
    "Some other components of this system could be examining the source of the article, examining publish dates. However, little effort has gone into optimizing the current model.\n",
    "\n",
    "__It is valuable to perform a grid search on the classifier parameters to find optimal values.__\n",
    "\n",
    "It is likely that this model is fitted to \"current\" events. We should hope that this can be more resilient and \"future-proof\".\n",
    "\n",
    "__This means that the model needs to be set up to consistently learn from data sets.__\n",
    "\n",
    "There are larger datasets out in the wild. This current model uses a subset of [Open Sources'](http://www.opensources.co/) dataset, using only 30,000 article bodies. This dataset alone has millions of articles and occupies ~30GB of memory. Scraping the web for articles online can produce multiple DB each day. This dataset is too large for many machines to hold in memory at once.\n",
    "\n",
    "__This means that the model needs to be scaled up to handle a larger set of data that may not fit in memory simultaneously.__\n",
    "\n",
    "Open Sources also supports the following tags instead of True/False:\n",
    "\n",
    "- Fake News (tag fake) Sources that entirely fabricate information, disseminate deceptive content, or grossly distort actual news reports\n",
    "\n",
    "- Satire (tag satire) Sources that use humor, irony, exaggeration, ridicule, and false information to comment on current events.\n",
    "\n",
    "- Extreme Bias (tag bias) Sources that come from a particular point of view and may rely on propaganda, decontextualized information, and opinions distorted as facts.\n",
    "\n",
    "- Conspiracy Theory (tag conspiracy): Sources that are well-known promoters of kooky conspiracy theories.\n",
    "\n",
    "- Rumor Mill (tag rumor) Sources that traffic in rumors, gossip, innuendo, and unverified claims.\n",
    "\n",
    "- State News (tag state) Sources in repressive states operating under government sanction.\n",
    "\n",
    "- Junk Science (tag junksci) Sources that promote pseudoscience, metaphysics, naturalistic fallacies, and other scientifically dubious claims.\n",
    "\n",
    "- Hate News (tag hate) Sources that actively promote racism, misogyny, homophobia, and other forms of discrimination.\n",
    "\n",
    "- Clickbait (tag clickbait) Sources that provide generally credible content, but use exaggerated, misleading, or questionable headlines, social media descriptions, and/or images.\n",
    "\n",
    "- Proceed With Caution (tag unreliable) Sources that may be reliable but whose contents require further verification.\n",
    "\n",
    "- Political (tag political) Sources that provide generally verifiable information in support of certain points of view or political orientations.\n",
    "\n",
    "- Credible (tag reliable) Sources that circulate news and information in a manner consistent with traditional and ethical practices in journalism (Remember: even credible sources sometimes rely on clickbait-style headlines or occasionally make mistakes. No news organization is perfect, which is why a healthy news diet consists of multiple sources of information).\n",
    "\n",
    "How reliably can a model be able to differentiate between dozen tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
