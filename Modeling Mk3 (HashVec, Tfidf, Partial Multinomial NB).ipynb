{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-core Learning\n",
    "----\n",
    "\n",
    "Another major problem with the initial model was the restriction to datasets that could fit inside memory. This means: \n",
    "  - Technically, we are severely limited in the number of possible data sources\n",
    "  - Practically, the model must be retrained with each time that new data is being processed\n",
    "    - Imagine running a model trained during the 2012 presidential election on the 2016\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, HashingVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_msgpack(\"./combined.msg\")\n",
    "df['fakeness'] = 0\n",
    "df.loc[df['type'] < 2, 'fakeness'] = 1\n",
    "df.groupby('fakeness')\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    290438\n",
       "1    171636\n",
       "Name: fakeness, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fakeness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = HashingVectorizer(n_features=2**18,\n",
    "                         alternate_sign=False,\n",
    "                         stop_words=ENGLISH_STOP_WORDS,\n",
    "                         ngram_range=(1,2))\n",
    "trans = TfidfTransformer()\n",
    "clf = MultinomialNB(alpha=0.250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(max_size=None, batch_size=10000):\n",
    "    if max_size is None:\n",
    "        max_size = df.shape[0]\n",
    "    counter = batch_size\n",
    "    while counter < max_size:\n",
    "        yield df.iloc[counter:counter+batch_size].content.values, \\\n",
    "               df.iloc[counter:counter+batch_size].fakeness.values\n",
    "        counter += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time 8.76163649559021\n",
      "Pos 15000\n",
      "Score 0.8398\n",
      "Accuracy: 83.98%\n",
      "Train time 9.653783798217773\n",
      "Pos 30000\n",
      "Score 0.8082\n",
      "Accuracy: 80.82000000000001%\n",
      "Train time 9.237140655517578\n",
      "Pos 45000\n",
      "Score 0.7992\n",
      "Accuracy: 79.92%\n",
      "Train time 9.591607332229614\n",
      "Pos 60000\n",
      "Score 0.7921333333333334\n",
      "Accuracy: 79.21333333333334%\n",
      "Train time 8.916282176971436\n",
      "Pos 75000\n",
      "Score 0.7913333333333333\n",
      "Accuracy: 79.13333333333334%\n",
      "Train time 8.801216125488281\n",
      "Pos 90000\n",
      "Score 0.7884666666666666\n",
      "Accuracy: 78.84666666666666%\n",
      "Train time 8.779746532440186\n",
      "Pos 105000\n",
      "Score 0.7882666666666667\n",
      "Accuracy: 78.82666666666667%\n",
      "Train time 8.794522523880005\n",
      "Pos 120000\n",
      "Score 0.7876666666666666\n",
      "Accuracy: 78.76666666666667%\n",
      "Train time 9.300930261611938\n",
      "Pos 135000\n",
      "Score 0.7863333333333333\n",
      "Accuracy: 78.63333333333333%\n",
      "Train time 9.719456434249878\n",
      "Pos 150000\n",
      "Score 0.7852666666666667\n",
      "Accuracy: 78.52666666666667%\n",
      "Train time 9.331478357315063\n",
      "Pos 165000\n",
      "Score 0.7857333333333333\n",
      "Accuracy: 78.57333333333332%\n",
      "Train time 9.788714170455933\n",
      "Pos 180000\n",
      "Score 0.7856666666666666\n",
      "Accuracy: 78.56666666666666%\n",
      "Train time 9.752736330032349\n",
      "Pos 195000\n",
      "Score 0.7854666666666666\n",
      "Accuracy: 78.54666666666667%\n",
      "Train time 9.918837070465088\n",
      "Pos 210000\n",
      "Score 0.785\n",
      "Accuracy: 78.5%\n",
      "Train time 9.520261526107788\n",
      "Pos 225000\n",
      "Score 0.7846666666666666\n",
      "Accuracy: 78.46666666666667%\n",
      "Train time 9.323880434036255\n",
      "Pos 240000\n",
      "Score 0.7844\n",
      "Accuracy: 78.44%\n",
      "Train time 8.8683762550354\n",
      "Pos 255000\n",
      "Score 0.7831333333333333\n",
      "Accuracy: 78.31333333333333%\n",
      "Train time 8.87432050704956\n",
      "Pos 270000\n",
      "Score 0.7834666666666666\n",
      "Accuracy: 78.34666666666666%\n",
      "Train time 9.05284309387207\n",
      "Pos 285000\n",
      "Score 0.7836\n",
      "Accuracy: 78.36%\n",
      "Train time 9.145346403121948\n",
      "Pos 300000\n",
      "Score 0.7835333333333333\n",
      "Accuracy: 78.35333333333332%\n",
      "Train time 9.195062398910522\n",
      "Pos 315000\n",
      "Score 0.7839333333333334\n",
      "Accuracy: 78.39333333333333%\n",
      "Train time 9.178198337554932\n",
      "Pos 330000\n",
      "Score 0.7834666666666666\n",
      "Accuracy: 78.34666666666666%\n",
      "Train time 8.857779264450073\n",
      "Pos 345000\n",
      "Score 0.7839333333333334\n",
      "Accuracy: 78.39333333333333%\n",
      "Train time 10.043846130371094\n",
      "Pos 360000\n",
      "Score 0.784\n",
      "Accuracy: 78.4%\n",
      "Train time 9.45966649055481\n",
      "Pos 375000\n",
      "Score 0.7838\n",
      "Accuracy: 78.38000000000001%\n",
      "Train time 9.116902828216553\n",
      "Pos 390000\n",
      "Score 0.7834666666666666\n",
      "Accuracy: 78.34666666666666%\n",
      "Train time 9.113727569580078\n",
      "Pos 405000\n",
      "Score 0.7834\n",
      "Accuracy: 78.34%\n",
      "Train time 9.57253384590149\n",
      "Pos 420000\n",
      "Score 0.7833333333333333\n",
      "Accuracy: 78.33333333333333%\n",
      "Train time 9.207021713256836\n",
      "Pos 435000\n",
      "Score 0.7832666666666667\n",
      "Accuracy: 78.32666666666667%\n",
      "Train time 6.975494861602783\n",
      "Pos 450000\n",
      "Score 0.7828\n",
      "Accuracy: 78.28%\n"
     ]
    }
   ],
   "source": [
    "test = df.iloc[:15000].content.values\n",
    "y_test = df.iloc[:15000].fakeness.values\n",
    "test_vect = vect.transform(test)\n",
    "test_tfidf = trans.fit_transform(test_vect)\n",
    "\n",
    "batches = iter_batches(batch_size=15000)\n",
    "for i, (x_train, y_train) in enumerate(batches):\n",
    "    tick = time.time()\n",
    "    x_vect = vect.transform(x_train)\n",
    "    x_tfidf = trans.transform(x_vect)\n",
    "    clf.partial_fit(x_tfidf, y_train, classes=[0, 1])\n",
    "\n",
    "    print(\"Train time\", time.time() - tick)\n",
    "    print(\"Pos\", (i + 1) * 15000)\n",
    "    print(\"Score\", clf.score(test_tfidf, y_test))\n",
    "    predicted = clf.predict(test_tfidf)\n",
    "    print(\"Accuracy: \" + str(np.mean(predicted == y_test) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.28%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(np.mean(predicted == y_test) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    factual       0.99      0.67      0.80      9408\n",
      "  fake news       0.64      0.99      0.78      5592\n",
      "\n",
      "avg / total       0.86      0.79      0.79     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted, target_names=['factual', 'fake news']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of Results\n",
    "----\n",
    "\n",
    "78% accuracy doesn't seem very reassuring.\n",
    "\n",
    "When looking at the classification report, we can think of the properties in the following ways:\n",
    "  - __Support__: The actual number of items with that tag\n",
    "  - __Precision__: Given a positive prediction from the classifier, how likely is it to be correct?\n",
    "  - __Recall__: Given a positive example, will the classifier detect it?\n",
    "  \n",
    "Upon closer inspection, these results actually look very promising. The recall value of factual articles is one of the _less_ important statistics. It is typically very easy to identify what is real, and there are many other means of doing this. We can look at the publisher, journalist, and the \"web of trust\" built around a piece of news and quickly identify whether the article is certainly accurate or suspect.\n",
    "\n",
    "On the other side of the coin, the reflected high recall for \"fake news\" is also promising. If the article appears suspect due to other measures (as listed above), there is a very high chance of the model confirming our suspicions.\n",
    "\n",
    "Why is the accuracy of this model so low?\n",
    "\n",
    "It is possible that the relative imbalance of this subset of the larger corpus influences the ability for the model to learn appropriately. With more than $3/5$ of the dataset being labeled likely factual, there is room for more \"fake news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "----\n",
    "\n",
    "### Dataset Improvements\n",
    "\n",
    "When initially working through the ~9 million articles in the dataset, I noticed significant problems with data corruption both in the CSV and after it was imported with pandas.\n",
    "\n",
    "There is a large space for improvement with input data sets, and this is luckily something that can be automated. I would be interested in catching a wide net of news sources, scraping them from their respective websites, and cleaning up any corruption that occurs during scraping.\n",
    "\n",
    "This would also solve another problem that was noticed: many of the documents from \"fake-news\" sites were not news articles in any way. Some were simply home pages, others were comment threads. I'm unsure how much these non-news documents influenced the output of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Improvements\n",
    "\n",
    "This model is missing some of the features commonly found in neural networks:\n",
    "- The ability to \"drop\" connections between neurons\n",
    "  - A possibly productive analogue would be the ability to mark specific nouns to be \"forgotten\" during training. We wouldn't want to train on the words \"Trump\", \"Putin\", and \"Russia\" too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
